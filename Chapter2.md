# Chapter 2 图形渲染管线

本章介绍渲染管线的不同阶段。

## 2.1 结构

管线的不同阶段并行执行。一个非管线系统被划分为$n$个管线化的阶段，那么执行速度会提升$n$倍。这一性能上的提升是使用管线的主要原因。管线的最终性能受制于最慢的阶段，这以阶段被称为瓶颈。

实时渲染管线可以被分为4个阶段：应用，几何处理，光栅化和像素处理。每个阶段本身也是一个管线，包括许多子阶段。这些阶段是功能性阶段，与具体的实现结构并不一样。一个功能性阶段只是指定了一个任务，但并不指定具体的实现方法。

渲染速度用FPS表示，也可以用Hz表示。另一种常见的衡量方式是渲染一个图像的时间，单位是毫秒。Hz用于硬件，如显示器。这些硬件的渲染速度是固定的。

应用阶段主要由软件实现，跑在通用CPU上。这一阶段通常包括碰撞检测，全局加速算法，动画，物理模拟等等。几何处理阶段处理变换，投影和其他所有几何操作，计算画什么，怎么画，画在哪。几何阶段运行在GPU上。光栅化阶段以组成三角形的三个顶点为输入，计算位于三角形内的所有像素，并将结果传到下一阶段。最终，像素处理阶段在每个像素上运行程序来计算该像素的颜色。该阶段还可能会执行深度测试，混合等操作。光栅化阶段和像素处理阶段也都由GPU处理。

## 2.2 应用阶段

开发者对应用阶段拥有完全的控制权。一些应用性的工作也可以交给GPU来完成，这通过计算着色器来实现。在应用阶段的末尾，需要渲染的几何体被传递给几何处理阶段。这些几何体就是渲染原型，即点，线和三角形。通过使用超标量结构，CPU也可以实现一定程度的并行性。应用阶段也负责处理用户的输入。诸如粒子剔除算法之类的加速算法也在这一阶段实现。

## 2.3 几何处理阶段

几何处理阶段操作每个三角形和每个顶点。该阶段又可以分为4个功能性阶段：顶点着色，投影，剪裁和屏幕映射。

### 2.3.1 顶点着色

顶点着色器的主要任务有2个：计算顶点的位置，计算程序员想要的任何定点输出数据，例如法向量和纹理坐标。传统上对一个对象的着色过程是在定点上计算颜色，这些颜色会在三角形上插值。因此，该顶点处理单元被称为顶点着色器。在现代GPU上，顶点着色器的功能更加通用，例如顶点动画。

顶点需要被转换到几个不同的空间，或者说坐标系。一个模型最初在自己的模型空间。模型通过模型变换转换到世界空间。一个模型可以有多个模型变换，这叫做实例化。世界空间内的模型经由视变换，被转换到摄像机空间（也叫视空间，或眼空间）。此时，摄像机朝向$z$轴负方向，$y$轴向上，$x$轴向右（也有人更习惯摄像机朝向$z$轴正方向）。

顶点着色器除了要计算顶点的位置，还要涉及材质和光的交互，也就是着色。一些计算发生在顶点着色器，还有一些计算发生在像素着色器。一些材质属性可以被存储在顶点上，如顶点的位置，法向量，颜色等等。顶点着色的结果（颜色，向量，纹理坐标）会被传递给光栅化阶段和像素处理阶段，插值后被用来着色。

顶点着色还包括投影和剪裁。视体积会被变换成一个单位立方体，范围是$(-1,-1,-1)$到$(1,1,1)$。也存在其他的范围，如$0 \leq z \leq 1$。单位立方体被称为规范视体积（*canonical view volume*）。顶点着色器先做投影。有两种常用的投影：正交投影个透视投影。投影变换用矩阵表达，该矩阵经常跟后续的变换矩阵连结。投影变换后，模型被转换到剪裁坐标，实际上也就是齐次坐标。这发生在除以$w$之前。顶点着色器必须输出齐次坐标。改变换之所以被叫做投影，是因为在最终显示图像时，$z$坐标被存在了$z$缓冲里，这相当于把模型从3维空间投影到了2维空间。

### 2.3.2 可选的顶点处理

上述顶点处理功能是每个管线都有的。也有一些可选的阶段，按顺序是曲面细分，几何着色，以及流输出。曲面细分包括hull着色器，曲面细分器，和domain着色器，用于定制细节程度。下一阶段是几何着色器，它输入各种几何原型，并输出新的顶点，可用来实现粒子生成和广告牌算法。最后一个阶段是流输出。它可以将处理好的顶点输出到一个临时的数组中。这些数据可以被CPU和GPU使用。

### 2.3.3 剪裁

原型依据单位立方体进行剪裁。剪裁使用齐次坐标。在透视空间，三角形上的值通常不是线性插值的。第4个坐标用来进行正确的插值和剪裁。然后进行透视除，将顶点转换到NDC空间。如前所述，NDC空间的范围是$(-1,-1,-1)$到$(1,1,1)$。最后是从NDC空间到屏幕空间的转换。

### 2.3.4 屏幕映射

$x$和$y$坐标会被转换到屏幕坐标。屏幕坐标和$z$坐标也被叫做窗口坐标。$z$坐标（OpenGL是$[-1,+1]$，DirectX是$[0,1]$）也会被映射到$\left[z_{1}, z_{2}\right]$，默认是$z_{1}=0$，$z_{2}=1$，不过不同的API可能会有不同的值。屏幕坐标和重新映射的$z$值被传递给光栅化阶段。

下面描述整数和浮点数如何与像素（和纹理坐标）关联。给定一个使用笛卡尔坐标系的水平像素数组，最左边的像素的左边界的坐标值是$0.0$。OpenGL使用该定义，DirectX10和后继版本也是用该定义。该像素的中心点是$0.5$。因此，范围是$[0,9]$的像素的跨度是$[0.0,10.0)$。转换如下：
$$d=\mathrm{f} 1 \mathrm{oor}(\mathrm{c})$$
$$c=d+0.5$$
其中$d$是像素的索引，$c$是像素的中心。另外尤其要注意的是，在OpenGL中，原点在左下角，而DirectX中的原点在左上角。

## 2.4 光栅化

光栅化的主要任务就是找到所有位于原型内的像素。它分为2个功能性的子阶段：三角形建立（也叫做原型装配）和三角形遍历。如何确定一个三角形是否覆盖一个像素依赖于管线的设定。例如最简单的点采样：如果一个像素的中心点位于三角形内，那么该像素就被认为处在三角形内。其他的方法包括超采样和多重采样。还有一种方法叫做保守光栅化。

### 2.4.1 三角形建立

该步骤计算微分，边方程等三角形数据。这些数据用于三角形遍历阶段和顶点插值。该阶段使用固定硬件实现。

### 2.4.2 三角形遍历

该阶段生成片段（*fragment*）。确定哪一个片段或者像素位于三角形内的过程被称作三角形遍历。透视正确的插值也发生在该阶段。

## 2.5 像素处理

该阶段包括像素着色和merging这2个阶段。

### 2.5.1 像素处理

该阶段进行着色计算。像素着色阶段是可编程的，程序员提供像素着色器（在OpenGL中叫做片段着色器）。纹理映射就发生在该阶段。

### 2.5.2 Merging

每个像素的颜色被存储在颜色缓冲里。merging阶段负责把片段着色器的输出与已经存储在颜色缓冲里的颜色进行组合，以得到最终的结果。这一阶段也叫做ROP。该阶段无法编程，但是高度可配置。

该阶段还负责解决可见性。通常的做法是使用$z$缓冲。然而，由于只是用一个简单的深度值，$z$缓冲无法处理半透明物体。*alpha*通道用来存储像素的相对透明度。

模板缓冲是一个离屏缓冲，可用来记录渲染原型的位置。它通常有8比特每像素。帧缓冲则包含了一个系统里的所有缓冲。

为了防止观察者看到绘制的过程，双缓冲技术被使用。绘制发生在离屏的后缓冲上。绘制完成后，交换后缓冲和前缓冲的内容。

## 2.6 管线总结

一个例子，略。上述管线并非唯一的管线，一个离线的渲染管线的例子是电影工业使用的微多边形管线。光线追踪和路径追踪也备受关注。固定函数管线已经被淘汰，本书假定所有的开发都基于可编程GPU。

## 拓展阅读

*OpenGL Programming Guide*（也叫做红书）详细描述了渲染管线和相关算法。